# -*- coding: utf-8 -*-
"""process_bank_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z00Z8NFt9GmXeTBx8vkF0vEYlnBw7xwy
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from typing import Tuple, Dict, Any

def categorize_score(score: int) -> str:
    """
    Categorizes credit score.

    Args:
        score (int): Credit score value.

    Returns:
        str: Category of the credit score.
    """
    if score <= 579:
        return 'poor'
    elif 580 <= score <= 669:
        return 'fair'
    elif 670 <= score <= 739:
        return 'good'
    elif 740 <= score <= 799:
        return 'very good'
    elif 800 <= score <= 850:
        return 'exceptional'

def age_cat(years: int) -> str:
    """
    Categorizes age.

    Args:
        years (int): Age in years.

    Returns:
        str: Age category.
    """
    if years <= 20:
        return '0-20'
    elif 20 < years <= 30:
        return '20-30'
    elif 30 < years <= 40:
        return '30-40'
    elif 40 < years <= 50:
        return '40-50'
    elif 50 < years <= 60:
        return '50-60'
    elif 60 < years <= 70:
        return '60-70'
    else:
        return '70+'

def split_data(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Splits the data into training and validation sets.

    Args:
        df (pd.DataFrame): The dataframe to split.
        target_col (str): The target column name.
        test_size (float): Proportion of the data to be used for validation.
        random_state (int): Random state for reproducibility.

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.
    """
    return train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])

def scale_numeric_features(train_inputs: pd.DataFrame, val_inputs: pd.DataFrame, numeric_cols: list) -> Tuple[pd.DataFrame, pd.DataFrame, MinMaxScaler]:
    """
    Scales numeric features using MinMaxScaler.

    Args:
        train_inputs (pd.DataFrame): Training inputs.
        val_inputs (pd.DataFrame): Validation inputs.
        numeric_cols (list): List of numeric columns.

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame, MinMaxScaler]: Scaled training and validation inputs, and the scaler instance.
    """
    scaler = MinMaxScaler().fit(train_inputs[numeric_cols])
    train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])
    val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])
    return train_inputs, val_inputs, scaler

def encode_categorical_features(train_inputs: pd.DataFrame, val_inputs: pd.DataFrame, categorical_cols: list) -> Tuple[pd.DataFrame, pd.DataFrame, OneHotEncoder]:
    """
    One-hot encodes categorical features.

    Args:
        train_inputs (pd.DataFrame): Training inputs.
        val_inputs (pd.DataFrame): Validation inputs.
        categorical_cols (list): List of categorical columns.

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame, OneHotEncoder]: Encoded training and validation inputs, and the encoder instance.
    """
    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(train_inputs[categorical_cols])
    encoded_cols = list(encoder.get_feature_names_out(categorical_cols))
    train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])
    val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])
    return train_inputs, val_inputs, encoder

def preprocess_data(raw_df: pd.DataFrame) -> pd.DataFrame:
    """
    Preprocesses the data.

    Args:
        raw_df (pd.DataFrame): The raw input dataframe.

    Returns:
        pd.DataFrame: Processed dataframe containing training, validation, and test data.
    """
    raw_df['CreditScoreCat'] = raw_df['CreditScore'].apply(categorize_score)
    raw_df['AgeCat'] = raw_df['Age'].apply(age_cat)

    train_df, val_df = split_data(raw_df, target_col='Exited')

    input_cols = raw_df.drop(['CustomerId', 'Surname', 'Age', 'CreditScore', 'Exited'], axis=1).columns
    target_col = 'Exited'
    train_inputs, train_targets = train_df[input_cols], train_df[target_col]
    val_inputs, val_targets = val_df[input_cols], val_df[target_col]

    numeric_cols = train_inputs.select_dtypes(exclude='object').columns.tolist()
    categorical_cols = train_inputs.select_dtypes(include='object').columns.tolist()

    train_inputs, val_inputs, scaler = scale_numeric_features(train_inputs, val_inputs, numeric_cols)
    train_inputs, val_inputs, encoder = encode_categorical_features(train_inputs, val_inputs, categorical_cols)

    train_inputs = train_inputs.drop(columns=categorical_cols)
    val_inputs = val_inputs.drop(columns=categorical_cols)

    return {
        'train_X': train_inputs,
        'train_y': train_targets,
        'val_X': val_inputs,
        'val_y': val_targets
    }

def preprocess_new_data(new_data: pd.DataFrame, scaler: MinMaxScaler, encoder: OneHotEncoder, numeric_cols: list, categorical_cols: list) -> pd.DataFrame:
    """
    Preprocesses new data using the existing scaler and encoder.

    Args:
        new_data (pd.DataFrame): The new data to preprocess.
        scaler (MinMaxScaler): The scaler instance.
        encoder (OneHotEncoder): The encoder instance.
        numeric_cols (list): List of numeric columns.
        categorical_cols (list): List of categorical columns.

    Returns:
        pd.DataFrame: The preprocessed new data.
    """
    new_data[numeric_cols] = scaler.transform(new_data[numeric_cols])
    encoded_cols = list(encoder.get_feature_names_out(categorical_cols))
    new_data[encoded_cols] = encoder.transform(new_data[categorical_cols])
    return new_data